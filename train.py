import os
import time
import datetime
import warnings
import librosa
import numpy as np
import pickle
import pandas as pd
import tensorflow as tf
import glob
from sklearn.utils import class_weight
from sklearn.model_selection import train_test_split
from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint, Callback
from keras.models import Model
from keras.layers import (Conv2D, BatchNormalization, MaxPooling2D, Dropout,
                          Flatten, Dense, Input, Add, GlobalAveragePooling2D, Activation)
from keras.optimizers import Adam
from keras.utils import to_categorical
from sklearn.preprocessing import StandardScaler

warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# GPU ë° Mixed Precision ì„¤ì •
print("\n" + "=" * 70)
print("GPU ì„¤ì •")
print("=" * 70)

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print(f"âœ… GPU ê°ì§€: {len(gpus)}ê°œ")
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ í™œì„±í™”")

        from tensorflow.keras import mixed_precision

        policy = mixed_precision.Policy('mixed_float16')
        mixed_precision.set_global_policy(policy)
        print("âœ… Mixed Precision í™œì„±í™”")
    except Exception as e:
        print(f"âš ï¸  ì„¤ì • ê²½ê³ : {e}")
else:
    print("âš ï¸  CPU ëª¨ë“œ")

print("=" * 70 + "\n")


def save_weights(computed_weights, manual_weights):
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    timestr = time.strftime('%Y%m%d-%H%M%S')
    directory = "weights"

    if not os.path.exists(directory):
        os.makedirs(directory)

    with open(os.path.join(directory, f'computed_weights_{timestr}.pkl'), 'wb') as f:
        pickle.dump(computed_weights, f)

    with open(os.path.join(directory, f'manual_weights_{timestr}.pkl'), 'wb') as f:
        pickle.dump(manual_weights, f)

    print(f"âœ… ê°€ì¤‘ì¹˜ ì €ì¥ ì™„ë£Œ: {directory}/")


def load_weights():
    """ì €ì¥ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê¸°"""
    directory = "weights"

    if not os.path.exists(directory):
        raise Exception(f"{directory} ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    computed_weights_files = glob.glob(os.path.join(directory, 'computed_weights_*.pkl'))
    manual_weights_files = glob.glob(os.path.join(directory, 'manual_weights_*.pkl'))

    if not computed_weights_files or not manual_weights_files:
        raise Exception("ì €ì¥ëœ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    computed_weights_files.sort()
    manual_weights_files.sort()

    with open(computed_weights_files[-1], 'rb') as f:
        loaded_computed_weights = pickle.load(f)

    with open(manual_weights_files[-1], 'rb') as f:
        loaded_manual_weights = pickle.load(f)

    return loaded_computed_weights, loaded_manual_weights


def adjust_class_weights_interactive(computed_weights, class_counts):
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ ì¡°ì •"""
    print("\n" + "=" * 70)
    print("í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ë° ìë™ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜")
    print("=" * 70)
    print(f"{'í´ë˜ìŠ¤ID':<10} {'í´ë˜ìŠ¤ëª…':<20} {'ìƒ˜í”Œ ìˆ˜':<12} {'ìë™ ê°€ì¤‘ì¹˜':<15}")
    print("-" * 70)

    class_names = {
        0: "air_conditioner", 1: "car_horn", 2: "children_playing",
        3: "dog_bark", 4: "drilling", 5: "engine_idling",
        6: "gun_shot", 7: "jackhammer", 8: "siren", 9: "street_music"
    }

    for class_id in sorted(computed_weights.keys()):
        count = class_counts.get(class_id, 0)
        weight = computed_weights[class_id]
        name = class_names.get(class_id, "unknown")
        print(f"{class_id:<10} {name:<20} {count:<12} {weight:<15.4f}")

    print("=" * 70)
    print("\nê°€ì¤‘ì¹˜ ì¡°ì • ì˜µì…˜:")
    print("1. ìë™ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ê¶Œì¥)")
    print("2. íŠ¹ì • í´ë˜ìŠ¤ì˜ ê°€ì¤‘ì¹˜ë§Œ ìˆ˜ë™ ì¡°ì •")
    print("3. ëª¨ë“  í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” í›„ ìˆ˜ë™ ì„¤ì •")

    choice = input("\nì„ íƒí•˜ì„¸ìš”(1/2/3, ê¸°ë³¸ê°’: 1): ").strip() or "1"
    manual_adjustments = {}

    if choice == "1":
        print("\nâœ… ìë™ ê³„ì‚°ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return manual_adjustments

    elif choice == "2":
        print("\nì¡°ì •í•  í´ë˜ìŠ¤IDë¥¼ ì…ë ¥í•˜ì„¸ìš”(ì‰¼í‘œë¡œ êµ¬ë¶„, ì˜ˆ: 0,3,6)")
        print("ì…ë ¥ ì—†ì´ Enterë¥¼ ëˆ„ë¥´ë©´ ìë™ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        class_input = input("í´ë˜ìŠ¤ID: ").strip()

        if not class_input:
            return manual_adjustments

        try:
            classes_to_adjust = [int(x.strip()) for x in class_input.split(',')]
        except ValueError:
            print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ìë™ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            return manual_adjustments

        for class_id in classes_to_adjust:
            if class_id not in computed_weights:
                print(f"âš ï¸  í´ë˜ìŠ¤{class_id}ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                continue

            current_weight = computed_weights[class_id]
            print(f"\ní´ë˜ìŠ¤ {class_id} ({class_names.get(class_id, 'unknown')})")
            print(f"  í˜„ì¬ ê°€ì¤‘ì¹˜: {current_weight:.4f}")
            print(f"  ìƒ˜í”Œ ìˆ˜: {class_counts.get(class_id, 0)}")

            try:
                multiplier = float(input(f"  ê°€ì¤‘ì¹˜ ë°°ìˆ˜ (ì˜ˆ: 1.5, 2.0): ").strip() or "1.0")
                manual_adjustments[class_id] = multiplier
                print(f"  â†’ ìƒˆ ê°€ì¤‘ì¹˜: {current_weight * multiplier:.4f}")
            except ValueError:
                print(f"  âš ï¸  ì˜ëª»ëœ ì…ë ¥. ì›ë˜ ê°€ì¤‘ì¹˜ ìœ ì§€.")

    elif choice == "3":
        print("\nëª¨ë“  í´ë˜ìŠ¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.")
        try:
            base_count = float(input("ê¸°ì¤€ ìƒ˜í”Œ ìˆ˜ (ê¸°ë³¸ê°’: ìµœëŒ€ ìƒ˜í”Œ ìˆ˜): ").strip() or max(class_counts.values()))

            for class_id in sorted(computed_weights.keys()):
                count = class_counts.get(class_id, 1)
                auto_weight = base_count / count
                print(f"\ní´ë˜ìŠ¤ {class_id} ({class_names.get(class_id, 'unknown')})")
                print(f"  ìƒ˜í”Œ ìˆ˜: {count}, ê¶Œì¥ ê°€ì¤‘ì¹˜: {auto_weight:.4f}")

                user_input = input(f"  ê°€ì¤‘ì¹˜ ì…ë ¥(Enter: ê¶Œì¥ê°’): ").strip()
                if user_input:
                    try:
                        new_weight = float(user_input)
                        manual_adjustments[class_id] = new_weight / computed_weights[class_id]
                    except ValueError:
                        print("  âš ï¸  ì˜ëª»ëœ ì…ë ¥. ìë™ê°’ ì‚¬ìš©.")
                else:
                    manual_adjustments[class_id] = auto_weight / computed_weights[class_id]
        except ValueError:
            print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. ìë™ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    return manual_adjustments


def spec_augment(mel_spectrogram, time_mask_param=20, freq_mask_param=20, num_masks=2):
    """SpecAugment ë°ì´í„° ì¦ê°•"""
    mel_spec = mel_spectrogram.copy()
    num_mel_channels, num_frames = mel_spec.shape

    for _ in range(num_masks):
        t = np.random.randint(0, time_mask_param)
        t0 = np.random.randint(0, num_frames - t)
        mel_spec[:, t0:t0 + t] = 0

    for _ in range(num_masks):
        f = np.random.randint(0, freq_mask_param)
        f0 = np.random.randint(0, num_mel_channels - f)
        mel_spec[f0:f0 + f, :] = 0

    return mel_spec


def importData(apply_augmentation=True):
    """ë°ì´í„° ë¡œë”© ë° ì¦ê°•"""
    data = pd.read_csv(r'C:\test\UrbanSound8K\UrbanSound8K\metadata\UrbanSound8K.csv')
    valid_data = data[['slice_file_name', 'fold', 'classID', 'classname']][data['end'] - data['start'] >= 0.0]
    valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')

    print(f'ğŸ“Š ë°ì´í„° ê°œìˆ˜: {len(valid_data)}')

    class_frequencies = {i: 0 for i in range(10)}
    D = []
    totalCount = 0

    print('ğŸ“‚ ë°ì´í„° ë¡œë”© ì‹œì‘...')

    for row in valid_data.itertuples():
        if totalCount % 100 == 0:
            print(f'   ì§„í–‰: {totalCount}/{len(valid_data)}', end='\r')

        y, sr = librosa.load(os.path.join(r'C:\test\UrbanSound8K\audio', row.path), duration=2.97, sr=22050)
        class_frequencies[row.classID] += 1

        ps = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=512, fmax=8000)
        ps = librosa.power_to_db(ps, ref=np.max)

        if ps.shape[1] < 128:
            ps = np.pad(ps, ((0, 0), (0, 128 - ps.shape[1])))
        elif ps.shape[1] > 128:
            ps = ps[:, :128]

        D.append((ps, row.classID))

        if apply_augmentation:
            for _ in range(2):
                augmented_ps = spec_augment(ps, time_mask_param=15, freq_mask_param=15, num_masks=2)
                D.append((augmented_ps, row.classID))

        totalCount += 1

    print(f'\nâœ… ë¡œë”© ì™„ë£Œ: ì›ë³¸ {totalCount}ê°œ â†’ ì¦ê°• í›„ {len(D)}ê°œ')
    return D, class_frequencies


def compute_class_weights(y):
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ìë™ ê³„ì‚°"""
    y_integers = np.argmax(y, axis=1)
    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_integers), y=y_integers)
    return dict(enumerate(class_weights))


class CustomEarlyStopping(Callback):
    """ì¡°ê¸° ì¢…ë£Œ ì½œë°±"""

    def __init__(self, threshold=0.97, patience=15, verbose=1, restore_best_weights=True):
        super(CustomEarlyStopping, self).__init__()
        self.stopped_epoch = 0
        self.threshold = threshold
        self.patience = patience
        self.verbose = verbose
        self.restore_best_weights = restore_best_weights
        self.wait = 0
        self.best = -np.Inf
        self.best_weights = None

    def on_train_begin(self, logs=None):
        self.wait = 0
        self.stopped_epoch = 0
        self.best = -np.Inf
        self.best_weights = self.model.get_weights()

    def on_epoch_end(self, epoch, logs=None):
        current = logs.get('val_accuracy')
        if current is None:
            return

        if current >= self.threshold:
            if current > self.best:
                self.best = current
                if self.restore_best_weights:
                    self.best_weights = self.model.get_weights()
            self.wait = 0
        else:
            if self.best >= self.threshold:
                self.wait += 1
                if self.wait >= self.patience:
                    self.stopped_epoch = epoch
                    self.model.stop_training = True
                    if self.restore_best_weights and self.verbose > 0:
                        print(f'\nâœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë³µì› (ì •í™•ë„: {self.best:.4f})')
                        self.model.set_weights(self.best_weights)

    def on_train_end(self, logs=None):
        if self.stopped_epoch > 0 and self.verbose > 0:
            print(f'Epoch {self.stopped_epoch + 1}: ì¡°ê¸° ì¢…ë£Œ')


def residual_block(x, filters, kernel_size=(3, 3), dropout_rate=0.3):
    """Residual Block"""
    fx = Conv2D(filters, kernel_size, padding='same')(x)
    fx = BatchNormalization()(fx)
    fx = Activation('relu')(fx)
    fx = Dropout(dropout_rate)(fx)

    fx = Conv2D(filters, kernel_size, padding='same')(fx)
    fx = BatchNormalization()(fx)

    if x.shape[-1] != filters:
        x = Conv2D(filters, (1, 1), padding='same')(x)
        x = BatchNormalization()(x)

    out = Add()([x, fx])
    out = Activation('relu')(out)
    return out


def build_model(input_shape=(128, 128, 1), dropout_rate=0.3, learning_rate=0.001):
    """ìµœì í™”ëœ ëª¨ë¸ ë¹Œë“œ"""
    inputs = Input(shape=input_shape)

    x = Conv2D(32, (3, 3), padding='same')(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2))(x)
    x = Dropout(dropout_rate)(x)

    x = residual_block(x, 64, dropout_rate=dropout_rate)
    x = MaxPooling2D((2, 2))(x)

    x = residual_block(x, 128, dropout_rate=dropout_rate)
    x = MaxPooling2D((2, 2))(x)

    x = residual_block(x, 256, dropout_rate=dropout_rate)

    x = GlobalAveragePooling2D()(x)

    x = Dense(256, activation='relu')(x)
    x = Dropout(0.5)(x)

    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)

    outputs = Dense(10, activation='softmax', dtype='float32')(x)

    model = Model(inputs=inputs, outputs=outputs)

    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss="categorical_crossentropy", metrics=['accuracy'])

    return model


if __name__ == '__main__':
    # 1. ë°ì´í„° ë¡œë”©
    print("\n" + "=" * 70)
    print("1ë‹¨ê³„: ë°ì´í„° ë¡œë”©")
    print("=" * 70)
    dataSet, class_frequencies = importData(apply_augmentation=True)

    X, y = zip(*dataSet)
    X = np.array([x.reshape((128, 128, 1)) for x in X])
    y = np.array(to_categorical(y, 10))

    # 2. ì •ê·œí™”
    print("\n" + "=" * 70)
    print("2ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”")
    print("=" * 70)
    X_flat = X.reshape(X.shape[0], -1)
    scaler = StandardScaler()
    X_normalized = scaler.fit_transform(X_flat)
    X = X_normalized.reshape(X.shape[0], 128, 128, 1)

    with open('scaler.pkl', 'wb') as f:
        pickle.dump(scaler, f)
    print("âœ… ì •ê·œí™” ì™„ë£Œ (scaler.pkl ì €ì¥)")

    # 3. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    print(f"âœ… ë°ì´í„° ë¶„í• : í•™ìŠµ {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸ {len(X_test)}ê°œ")

    # 4. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •
    print("\n" + "=" * 70)
    print("3ë‹¨ê³„: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì„¤ì •")
    print("=" * 70)

    computed_weights = compute_class_weights(y_train)

    # ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì‹œë„
    try:
        loaded_computed_weights, loaded_manual_adjustments = load_weights()
        print("âœ… ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        use_saved = input("ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ì˜ˆ/ì•„ë‹ˆì˜¤, ê¸°ë³¸ê°’: ì˜ˆ): ").strip().lower()

        if use_saved == "" or use_saved == "ì˜ˆ":
            computed_weights = loaded_computed_weights
            manual_adjustments = loaded_manual_adjustments
            print("âœ… ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        else:
            manual_adjustments = adjust_class_weights_interactive(computed_weights, class_frequencies)
    except Exception as e:
        print(f"â„¹ï¸  ì €ì¥ëœ ê°€ì¤‘ì¹˜ ì—†ìŒ: {e}")
        print("ìƒˆë¡œìš´ ê°€ì¤‘ì¹˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n")
        manual_adjustments = adjust_class_weights_interactive(computed_weights, class_frequencies)

    # ìˆ˜ë™ ì¡°ì • ì ìš©
    for class_id, multiplier in manual_adjustments.items():
        computed_weights[class_id] *= multiplier

    print("\nğŸ“Š ìµœì¢… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
    for class_id, weight in sorted(computed_weights.items()):
        print(f"  í´ë˜ìŠ¤ {class_id}: {weight:.4f}")

    # ê°€ì¤‘ì¹˜ ì €ì¥
    save_weights(computed_weights, manual_adjustments)

    # 5. Callbacks ì„¤ì •
    print("\n" + "=" * 70)
    print("4ë‹¨ê³„: í•™ìŠµ ì¤€ë¹„")
    print("=" * 70)

    log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)

    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)

    checkpoint_filepath = 'best_model_complete.h5'
    model_checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_best_only=True,
                                       monitor='val_accuracy', mode='max', verbose=1)

    custom_early_stopping = CustomEarlyStopping(patience=15, threshold=0.96,
                                                restore_best_weights=True, verbose=1)

    # 6. ëª¨ë¸ ìƒì„±
    print("\nğŸ—ï¸  ëª¨ë¸ ìƒì„± ì¤‘...")
    print("   í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print("   - Dropout Rate: 0.3")
    print("   - Learning Rate: 0.001")

    model = build_model(
        input_shape=(128, 128, 1),
        dropout_rate=0.3,
        learning_rate=0.001
    )

    print("\nğŸ“‹ ëª¨ë¸ êµ¬ì¡°:")
    model.summary()

    # 7. í•™ìŠµ ì‹œì‘
    print("\n" + "=" * 70)
    print("5ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ")
    print("=" * 70)

    start_time = time.time()

    history = model.fit(
        x=X_train,
        y=y_train,
        epochs=200,
        batch_size=64,
        validation_data=(X_test, y_test),
        callbacks=[tensorboard, custom_early_stopping, reduce_lr, model_checkpoint],
        class_weight=computed_weights,  # â† ê°€ì¤‘ì¹˜ ì ìš©!
        verbose=1
    )

    elapsed_time = time.time() - start_time

    # 8. í‰ê°€
    print("\n" + "=" * 70)
    print("6ë‹¨ê³„: ëª¨ë¸ í‰ê°€")
    print("=" * 70)
    score = model.evaluate(x=X_test, y=y_test, verbose=1)

    print('\n' + "=" * 70)
    print('âœ… í•™ìŠµ ì™„ë£Œ!')
    print("=" * 70)
    print(f'â±ï¸  ì´ í•™ìŠµ ì‹œê°„: {elapsed_time / 3600:.2f}ì‹œê°„ ({elapsed_time / 60:.1f}ë¶„)')
    print(f'ğŸ“‰ Test Loss: {score[0]:.4f}')
    print(f'ğŸ¯ Test Accuracy: {score[1]:.4f} ({score[1] * 100:.2f}%)')
    print("=" * 70)

    # 9. ëª¨ë¸ ì €ì¥
    timestr = time.strftime('%Y%m%d-%H%M%S')
    modelName = f'complete-sound-classification-{timestr}.h5'
    model_directory = 'models'

    if not os.path.exists(model_directory):
        os.makedirs(model_directory)

    model.save(os.path.join(model_directory, modelName))
    print(f'\nğŸ’¾ ëª¨ë¸ ì €ì¥: {os.path.join(model_directory, modelName)}')
    print('âœ¨ ëª¨ë“  ì‘ì—… ì™„ë£Œ!')
